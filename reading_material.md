# Reading and video material
Author: "Zoltan Papp"

Date: '2021-02-07'

Courses using this material are:
  
  - Data Science 1 (ML1): Machine Learning Concepts, Business Analytics, Central Euoropean University (CEU)
  - Data Science 2 (ML2): Machine Learning Tools, Business Analytics, Central Euoropean University (CEU)
  - Data Analysis 3 for Finance (ML1 and ML2): Machine Learning, Finance, Central Euoropean University (CEU)
  - Data mining techniques (ML1 and ML2), Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics (BME)

The course is building on the book Elements of statistical learning (ESLII going forward). Free pdf is available at https://web.stanford.edu/~hastie/Papers/ESLII.pdf. Only a small part of the book is actually required for the course. Below you will find all the chapters (page numbers) that are recommended. You can find the same references in the slides.

In addition to that, numerous other written and video sources are listed per topic. 

**Only material discussed during the course is part of the evaluation and only to the level we discussed it during the course. Any material listed here that goes beyond that, is solely meant as background information on the topic.**

### Material in addition to the slides for ML1
#### Bias and Variance
  - https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229

#### K-nearest neighbor:
  - Online interactive demo at: http://vision.stanford.edu/teaching/cs231n-demos/knn/

#### K-means clustering:
  - ESLII 14.3.11 Practical Issues (page 518-519)
  - ESLII 14.3.9 Vector Quantization (page 514-515)
  - Online interactive demo at: https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/
  
#### Principal Component Analysis:
  - https://towardsdatascience.com/introduction-to-principle-component-analysis-d705d27b88b6
  - https://www.youtube.com/watch?v=TJdH6rPA-TI
  - [optional] Eigenvectors and eigenvalues: https://www.youtube.com/watch?v=PFDu9oVAE-g


### Material in addition to the slides for ML2
#### Tree based methods:
  - ESLII 9.2 Tree-Based Methods (page 305-310)

#### Bootstrap aggregation:
  - ESLII 8.7 Bagging (page 282-288)

#### Random forest:
  - ESLII 15 Random Forest (page 587-602)

#### Boosting:
  - ESLII 10.1 Boosting Methods (page 337-341)

#### Gradient boosting:
  - ESLII 10.10.2 Gradient Boosting (page 359-361)

#### Support vector machines:
  - Read ESLII 12.1-12.2 Tree-Based Methods (page 417-422)

#### Neural networks:
  - ESLII 11.3, 11.4, 11.5, 11.6 Neural Networks (page 392-404)
  - 3BLUE1BROWN SERIES: What is backpropagation really doing? https://www.youtube.com/watch?v=Ilg3gGewQ5U
  - 3BLUE1BROWN SERIES: Backpropagation calculus https://www.youtube.com/watch?v=Ilg3gGewQ5U&t=699s
  - Batch normalization: https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c

### Further sources that are beyond the scope of these courses:
These are not required for the course.

  - Exploratory Data Analysis, John Tukey
  - Data Preparation for Data Mining, Dorian Pyle
  - Econometric Analysis by William H. Greene: this book provides a mathematical background and is far beyound the scope of our course. The appendix also has a nice summary of Matrix algebra, Probability and distribution theory and other related topics.
  - Introduction to Evolutionary Computing, A.E. Eiben, J.E. Smith





